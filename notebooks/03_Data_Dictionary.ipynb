{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6911ff",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>游닂 Complete Feature Dictionary (English)</strong></summary>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Group 1: Bibliographic Features (The \"What\" and \"When\")\n",
    "1.  **doi**:\n",
    "    *   **Meaning:** The unique identifier of the article.\n",
    "    *   **Importance:** Not a feature for the model, but the primary key to join all our data.\n",
    "2.  **publication_year**:\n",
    "    *   **Meaning:** The year the article was published.\n",
    "    *   **Importance:** Provides temporal context. Publishing and retraction practices change over time.\n",
    "    *   **Hypothesis:** The retraction rate may have increased in recent years due to better detection tools or the pressure to publish.\n",
    "3.  **article_type**:\n",
    "    *   **Meaning:** The type of publication (e.g., 'article', 'conference', 'review').\n",
    "    *   **Importance:** Essential for comparing \"apples to apples.\" The standards of rigor are different for each type.\n",
    "4.  **is_open_access**:\n",
    "    *   **Meaning:** A boolean (1/0) indicating if the article is open access.\n",
    "    *   **Importance:** Represents the journal's business model.\n",
    "    *   **Hypothesis:** Predatory journals often use a \"pay-to-publish\" open-access model, which could correlate with a higher retraction rate. That is, is there a correlation between the access model (and its potential lack of rigor in some cases) and retractions?\n",
    "\n",
    "### Group 2: Authorship Features (The \"Who\")\n",
    "1.  **author_count**:\n",
    "    *   **Meaning:** Total number of authors.\n",
    "    *   **Importance:** Measures the size of the research team.\n",
    "    *   **Hypothesis:** Anomalous numbers (very high or very low) could be a sign of \"paper mills\" or fraudulent authorships.\n",
    "2.  **institution_count**:\n",
    "    *   **Meaning:** Number of unique research institutions involved.\n",
    "    *   **Importance:** Measures the diversity of the collaboration.\n",
    "3.  **country_count**:\n",
    "    *   **Meaning:** Number of unique countries involved.\n",
    "    *   **Importance:** Similar to the previous one, but at a geopolitical level.\n",
    "4.  **first_author_country**:\n",
    "    *   **Meaning:** The country of the first author.\n",
    "    *   **Importance:** A strong contextual signal, as the first author usually leads the research.\n",
    "    *   **Hypothesis:** Certain national scientific policies could correlate with higher retraction rates.\n",
    "5.  **is_international_collaboration**:\n",
    "    *   **Meaning:** A boolean (1/0) if more than one country is involved.\n",
    "    *   **Importance:** A simple and powerful feature that summarizes international collaboration.\n",
    "\n",
    "### Group 3: Publication Venue Features (The \"Where\")\n",
    "1.  **journal_name**:\n",
    "    *   **Meaning:** Name of the journal or conference.\n",
    "    *   **Importance:** Useful for exploratory analysis and for understanding the model's results.\n",
    "2.  **publisher**:\n",
    "    *   **Meaning:** The publishing organization of the journal (e.g., 'Elsevier', 'Hindawi').\n",
    "    *   **Importance:** A very powerful feature. As we saw, a few publishers account for a large number of retractions.\n",
    "    *   **Hypothesis:** The business model and review standards of certain publishers are key predictors of retraction risk.\n",
    "3.  **is_publisher_missing**:\n",
    "    *   **Meaning:** A boolean flag (1/0) that is 1 (True) if a publisher could not be identified for the article, and 0 (False) if it was found.\n",
    "    *   **Importance:** Acts as a proxy for the \"legitimacy\" of the source. Serious, well-indexed publications almost always have a clear publisher. Its absence is a red flag.\n",
    "    *   **Hypothesis:** The lack of an identifiable publisher (a value of 1) correlates with a higher risk of retraction, as it may indicate that the article comes from a less-established source, a dubious conference, or a predatory journal.\n",
    "4.  **source_id**:\n",
    "    *   **Meaning:** The unique OpenAlex ID for the journal/source.\n",
    "    *   **Importance:** Not for the current model, but it's an investment for the future. We save it to be able to enrich the dataset later if we find a reliable source of journal metrics.\n",
    "\n",
    "### Group 4: Content Features (The \"How\" - NLP)\n",
    "1.  **title** and **abstract**:\n",
    "    *   **Meaning:** The text of the title and abstract (cleaned of retraction notices).\n",
    "    *   **Importance:** They are the raw material for creating more complex NLP features (like embeddings).\n",
    "2.  **is_abstract_missing**:\n",
    "    *   **Meaning:** A boolean flag (1/0) that is 1 (True) if the article does not have a real, clean abstract, and 0 (False) if it does.\n",
    "    *   **Importance:** Measures the \"completeness\" of the article's record. A serious research paper almost always includes an abstract.\n",
    "    *   **Hypothesis:** The absence of an abstract is an anomalous characteristic and could be associated with lower-quality works, conference summaries, or fraudulent articles that avoid giving a clear summary of their methods and results.\n",
    "3.  **title_length** and **abstract_length**:\n",
    "    *   **Meaning:** The number of characters in the title and in the actual abstract.\n",
    "    *   **Importance:** Simple measures of text structure.\n",
    "    *   **Hypothesis:** Fraudulent or low-quality works might have abnormally short or long abstracts or titles.\n",
    "4.  **n_concepts**:\n",
    "    *   **Meaning:** The number of topics or concepts that OpenAlex associates with the article.\n",
    "    *   **Importance:** Measures thematic breadth.\n",
    "    *   **Hypothesis:** \"Topic stuffing.\" An article that claims to cover too many things could be a sign of a lack of focus or an attempt to deceive.\n",
    "5.  **top_concept_level**:\n",
    "    *   **Meaning:** The level of specificity of the main concept (0=very general, 5=very specific).\n",
    "    *   **Importance:** Measures the depth of the topic.\n",
    "    *   **Hypothesis:** It might be easier to publish fraudulent works on very general and vague topics (low level) than on very specific and technical topics (high level).\n",
    "\n",
    "### Group 5: Impact Features (The \"So What\")\n",
    "1.  **n_references**:\n",
    "    *   **Meaning:** The number of articles this work cites in its bibliography.\n",
    "    *   **Importance:** A proxy for the background research work.\n",
    "    *   **Hypothesis:** Anomalous numbers (very few or very many) could be a sign of a careless or fraudulent work.\n",
    "2.  **citations_in_first_2_years**:\n",
    "    *   **Meaning:** An integer representing the total citations an article received during its first two years of life (the year of publication and the following one).\n",
    "    *   **Importance:** It is a measure of early impact that is temporally controlled, which prevents data leakage by not counting citations that occurred after an article was retracted. It is methodologically much more robust than the total citation count.\n",
    "    *   **Hypothesis:** High-quality (and low-risk) articles tend to accumulate citations in a healthy and steady manner from the beginning. Problematic articles might show anomalous citation patterns: either zero impact (no one cites them) or, in cases of organized fraud, a suspicious peak of self-citations in the initial phase.\n",
    "\n",
    "### Features We Don't Have Yet\n",
    "1.  **journal_h_index**:\n",
    "    *   **Meaning:** A metric that combines the productivity and impact of a journal. A high number indicates greater prestige.\n",
    "    *   **Importance (Theoretical):** It was our best feature to numerically measure the \"rigor\" of a journal.\n",
    "    *   **Hypothesis (Strong but unverified):** A low H-Index correlates strongly with a higher risk of retraction.\n",
    "    *   **Current Status:** Discarded for now due to the difficulty of obtaining it reliably and scalably, but we are keeping it on our \"radar\" thanks to saving the `source_id`.\n",
    "2.  **avg_author_works_count**:\n",
    "    *   **Meaning:** The average of the total number of publications for each author of the article. It measured the average \"experience\" or \"productivity\" of the team.\n",
    "    *   **Importance (Theoretical):** It was a numerical proxy for the history and reputation of the author team.\n",
    "    *   **Hypothesis:** Retracted articles might be written by teams with a significantly lower average of previous publications (novice or fraudulent authors).\n",
    "    *   **Reason for Discarding:** Computational Infeasibility. The OpenAlex API does not provide the author's `works_count` in the article query. Obtaining it would require an extra API call for each author of each article (~250,000+ additional calls), which is too costly and slow for the value it provides.\n",
    "\n",
    "### Features We Initially Planned to Use But Ultimately Discarded\n",
    "1.  **is_abstract_retraction_notice**:\n",
    "    *   **Meaning:** A boolean (1/0) indicating if the abstract field contained a retraction notice.\n",
    "    *   **Importance:** It is a meta-feature about data quality.\n",
    "    *   **Hypothesis:** The fact that the publisher replaces the abstract is a strong signal, although it occurs after the retraction (which is why we discarded it). For the model, it could capture subtle patterns about how different publishers handle retractions.\n",
    "\n",
    "The next two were replaced by `citations_in_first_2_years` to avoid data leakage.\n",
    "\n",
    "2.  **citation_count_total**:\n",
    "    *   **Meaning:** The total number of times the article has been cited.\n",
    "    *   **Importance:** A classic measure of impact.\n",
    "3.  **citations_per_year**:\n",
    "    *   **Meaning:** Total citations divided by the \"age\" of the article.\n",
    "    *   **Importance:** A much fairer, normalized measure of impact. It measures the \"speed\" at which an article accumulates citations.\n",
    "    *   **Hypothesis:** Fraudulent articles might have an initial peak of citations that then drops off quickly, or simply a very low citation speed.\n",
    "\n",
    "---\n",
    "\n",
    "### From the `df_retraction` after cleaning, we have these 21 columns and 56,046 rows:\n",
    "\n",
    "```\n",
    "Index(['record_id', 'title', 'subject', 'institution', 'journal', 'publisher',\n",
    "'country', 'author', 'urls', 'article_type', 'retraction_date',\n",
    "'retraction_doi', 'retraction_pub_med_id', 'original_paper_date',\n",
    "'original_paper_doi', 'original_paper_pub_med_id', 'retraction_nature',\n",
    "'reason', 'paywalled', 'notes', 'year'],\n",
    "dtype='object')\n",
    "```\n",
    "\n",
    "### Columns We DID Use (Directly or Indirectly)\n",
    "*   **`original_paper_doi`**:\n",
    "    *   **Usage:** Fundamental. It's our \"master key,\" the shopping list of DOIs we use to query the OpenAlex API and enrich the data.\n",
    "*   **`title`, `subject`, `institution`, `journal`, `publisher`, `country`, `author`, `article_type`, `original_paper_date (year)`**:\n",
    "    *   **Usage:** Inspiration and Validation. We don't use their data directly for the model (because we prefer the clean data from the API), but they were crucial for:\n",
    "        1.  **Formulating hypotheses:** Analyzing these columns helped us decide which features were important (publisher, country, etc.).\n",
    "        2.  **Validating the extraction:** We compared the data from these columns with what we get from the API to ensure our extractor works correctly.\n",
    "*   **`paywalled`**:\n",
    "    *   **Usage:** Inspiration. It led us to create the `is_open_access` feature from the API, which is a more reliable and standardized version.\n",
    "\n",
    "### Columns We WILL Add to the Final Dataset\n",
    "*   **`retraction_nature`**:\n",
    "    *   **Usage:** Target Definition. We use it to filter and keep only the cases that are \"Retraction\" or \"Expression of concern,\" thus defining what a \"bad\" event we want to predict is.\n",
    "*   **`reason`**:\n",
    "    *   **Usage:** The Crown Jewel. Although not a direct predictive feature, it is crucial for post-model analysis. Once the model identifies a paper as \"high risk,\" we can look at this column in our training data to understand why similar articles were retracted (e.g., \"Fake Peer Review,\" \"Paper Mill\"). It inspires feature engineering and enriches the project's narrative.\n",
    "\n",
    "### Columns We DID NOT Use (and why)\n",
    "*   **`record_id`**:\n",
    "    *   **Reason:** It's an internal identifier for Retraction Watch. It has no predictive value and is not a useful key for joining with other databases.\n",
    "*   **`urls`**:\n",
    "    *   **Reason:** Too heterogeneous and unstructured. The DOI URL already gives us the canonical link to the article.\n",
    "*   **`retraction_date`**:\n",
    "    *   **Reason:** Data Leakage. This is the date the event occurred. We cannot use information from the future to predict the past. Our model must predict the risk of retraction at the time of publication, when this date does not yet exist.\n",
    "*   **`retraction_doi`, `retraction_pub_med_id`**:\n",
    "    *   **Reason:** They are the identifiers of the retraction notice, not the original paper. They are not relevant for analyzing the characteristics of the article itself.\n",
    "*   **`original_paper_pub_med_id`**:\n",
    "    *   **Reason:** Redundant. The `original_paper_doi` is the universal identifier we have chosen as our primary key.\n",
    "*   **`notes`**:\n",
    "    *   **Reason:** Unstructured free text. It contains valuable information for manual investigation but is very difficult to process into a quantitative feature useful for the model. We discarded it for pragmatic reasons.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d3c7f7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>游닂 Diccionario completo de features (Espa침ol)</strong></summary>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Grupo 1: Caracter칤sticas Bibliogr치ficas (El \"Qu칠\" y \"Cu치ndo\")\n",
    "1. doi:\n",
    "- Significado: El identificador 칰nico del art칤culo.\n",
    "- Importancia: No es una feature para el modelo, sino la llave primaria para unir todos nuestros datos.\n",
    "2. publication_year:\n",
    "- Significado: A침o en que se public칩 el art칤culo.\n",
    "- Importancia: Aporta contexto temporal. Las pr치cticas de publicaci칩n y retractaci칩n cambian con el tiempo.\n",
    "- Hip칩tesis: La tasa de retractaciones puede haber aumentado en los 칰ltimos a침os debido a mejores herramientas de detecci칩n o a la presi칩n por publicar.\n",
    "3. article_type:\n",
    "- Significado: El tipo de publicaci칩n (ej: 'article', 'conference', 'review').\n",
    "- Importancia: Esencial para comparar \"manzanas con manzanas\". Los est치ndares de rigor son diferentes para cada tipo.\n",
    "4. is_open_access:\n",
    "- Significado: Booleano (1/0) que indica si el art칤culo es de acceso abierto.\n",
    "- Importancia: Representa el modelo de negocio de la revista.\n",
    "- Hip칩tesis: Las revistas depredadoras a menudo usan un modelo \"paga por publicar\" de acceso abierto, lo que podr칤a correlacionarse con una mayor tasa de retractaci칩n. Es decir, 쯘xiste una correlaci칩n entre el modelo de acceso (y su posible falta de rigor en algunos casos) y las retractaciones?\n",
    "### Grupo 2: Caracter칤sticas de Autor칤a (El \"Qui칠n\")\n",
    "1. author_count:\n",
    "- Significado: N칰mero total de autores.\n",
    "- Importancia: Mide el tama침o del equipo de investigaci칩n.\n",
    "- Hip칩tesis: N칰meros an칩malos (muy altos o muy bajos) podr칤an ser una se침al de \"paper mills\" o autor칤as fraudulentas.\n",
    "2. institution_count:\n",
    "- Significado: N칰mero de instituciones de investigaci칩n 칰nicas involucradas.\n",
    "- Importancia: Mide la diversidad de la colaboraci칩n.\n",
    "3. country_count:\n",
    "- Significado: N칰mero de pa칤ses 칰nicos involucrados.\n",
    "- Importancia: Similar al anterior, pero a nivel geopol칤tico.\n",
    "4. first_author_country:\n",
    "- Significado: El pa칤s del primer autor.\n",
    "- Importancia: Fuerte se침al contextual, ya que el primer autor suele liderar la investigaci칩n.\n",
    "- Hip칩tesis: Ciertas pol칤ticas cient칤ficas nacionales podr칤an correlacionarse con mayores tasas de retractaci칩n.\n",
    "5. is_international_collaboration:\n",
    "- Significado: Booleano (1/0) si hay m치s de un pa칤s involucrado.\n",
    "- Importancia: Feature simple y potente que resume la colaboraci칩n internacional.\n",
    "### Grupo 3: Caracter칤sticas del Lugar de Publicaci칩n (El \"D칩nde\")\n",
    "1. journal_name:\n",
    ". Significado: Nombre de la revista o conferencia.\n",
    "- Importancia: 칔til para el an치lisis exploratorio y para entender los resultados del modelo.\n",
    "2. publisher:\n",
    "- Significado: La editorial que publica la revista (ej: 'Elsevier', 'Hindawi').\n",
    "- Importancia: Feature potent칤sima. Como vimos, unas pocas editoriales concentran un gran n칰mero de retractaciones.\n",
    "- Hip칩tesis: El modelo de negocio y los est치ndares de revisi칩n de ciertas editoriales son un predictor clave del riesgo de retractaci칩n.\n",
    "3. is_publisher_missing:\n",
    "- Significado: Un flag booleano (1/0) que es 1 (Verdadero) si no se pudo identificar un editor para el art칤culo, y 0 (Falso) si s칤 se encontr칩.\n",
    "- Importancia: Act칰a como un proxy de la \"legitimidad\" de la fuente. Las publicaciones serias y bien indexadas casi siempre tienen un editor claro. Su ausencia es una se침al de alerta.\n",
    "- Hip칩tesis: La falta de un editor identificable (un valor de 1) se correlaciona con un mayor riesgo de retractaci칩n, ya que puede indicar que el art칤culo proviene de una fuente poco establecida, una conferencia dudosa o una revista depredadora.\n",
    "3. source_id:\n",
    "- Significado: El ID 칰nico de OpenAlex para la revista/fuente.\n",
    "- Importancia: No es para el modelo actual, pero es una inversi칩n de futuro. La guardamos para poder enriquecer el dataset m치s adelante si encontramos una fuente fiable de m칠tricas de revistas.\n",
    "### Grupo 4: Caracter칤sticas de Contenido (El \"C칩mo\" - NLP)\n",
    "1. title y abstract:\n",
    "- Significado: El texto del t칤tulo y del resumen (limpio de avisos de retractaci칩n).\n",
    "- Importancia: Son la materia prima para crear features de NLP m치s complejas (como embeddings).\n",
    "2. is_abstract_missing:\n",
    "- Significado: Un flag booleano (1/0) que es 1 (Verdadero) si el art칤culo no tiene un resumen (abstract) real y limpio, y 0 (Falso) si lo tiene.\n",
    "- Importancia: Mide la \"completitud\" del registro del art칤culo. Un trabajo de investigaci칩n serio casi siempre incluye un abstract.\n",
    "- Hip칩tesis: La ausencia de un abstract es una caracter칤stica an칩mala y podr칤a estar asociada con trabajos de menor calidad, res칰menes de conferencias, o art칤culos fraudulentos que evitan dar un resumen claro de sus m칠todos y resultados.\n",
    "3. title_length y abstract_length:\n",
    "- Significado: El n칰mero de caracteres en el t칤tulo y en el abstract real.\n",
    "- Importancia: Medidas simples de la estructura del texto.\n",
    "- Hip칩tesis: Trabajos fraudulentos o de baja calidad podr칤an tener abstracts o t칤tulos anormalmente cortos o largos.\n",
    "4. n_concepts:\n",
    "- Significado: N칰mero de temas o conceptos que OpenAlex asocia al art칤culo.\n",
    "- Importancia: Mide la amplitud tem치tica.\n",
    "- Hip칩tesis: \"Topic stuffing\". Un art칤culo que dice tratar sobre demasiadas cosas podr칤a ser una se침al de falta de enfoque o de intento de enga침o.\n",
    "5. top_concept_level:\n",
    "- Significado: El nivel de especificidad del concepto principal (0=muy general, 5=muy espec칤fico).\n",
    "- Importancia: Mide la profundidad del tema.\n",
    "- Hip칩tesis: Podr칤a ser m치s f치cil publicar trabajos fraudulentos sobre temas muy generales y vagos (nivel bajo) que sobre temas muy espec칤ficos y t칠cnicos (nivel alto).\n",
    "### Grupo 5: Caracter칤sticas de Impacto (El \"Y Qu칠\")\n",
    "1. n_references:\n",
    "- Significado: El n칰mero de art칤culos que este trabajo cita en su bibliograf칤a.\n",
    "- Importancia: Proxy del trabajo de investigaci칩n de fondo.\n",
    "- Hip칩tesis: N칰meros an칩malos (muy pocos o much칤simos) podr칤an ser una se침al de un trabajo descuidado o fraudulento.\n",
    "2. citations_in_first_2_years:\n",
    "- Significado: Un n칰mero entero que representa el total de citas que un art칤culo recibi칩 durante sus primeros dos a침os de vida (el a침o de publicaci칩n y el siguiente).\n",
    "- Importancia: Es una medida de impacto temprano que est치 controlada temporalmente, lo que evita la fuga de datos (data leakage) al no contar citas que ocurrieron despu칠s de que un art칤culo fuera retractado. Es metodol칩gicamente mucho m치s robusta que el conteo total de citas.\n",
    "- Hip칩tesis: Los art칤culos de alta calidad (y bajo riesgo) tienden a acumular citas de forma saludable y constante desde el principio. Los art칤culos problem치ticos podr칤an mostrar patrones de citaci칩n an칩malos: o bien un impacto nulo (nadie los cita) o, en casos de fraude organizado, un pico de auto-citaciones sospechoso en la fase inicial.\n",
    "\n",
    "### Features que todav칤a no tenemos\n",
    "1. journal_h_index:\n",
    "- Significado: M칠trica que combina la productividad y el impacto de una revista. Un n칰mero alto indica mayor prestigio.\n",
    "- Importancia (Te칩rica): Era nuestra mejor feature para medir num칠ricamente el \"rigor\" de una revista.\n",
    "- Hip칩tesis (Fuerte pero no verificada): Un H-Index bajo se correlaciona fuertemente con un mayor riesgo de retractaci칩n.\n",
    "- Estado Actual: Descartada por ahora debido a la dificultad de obtenerla de forma fiable y escalable, pero la conservamos en nuestro \"radar\" gracias a que guardamos el source_id.\n",
    "2. avg_author_works_count:\n",
    "- Significado: La media del n칰mero total de publicaciones de cada autor del art칤culo. Med칤a la \"experiencia\" o \"productividad\" promedio del equipo.\n",
    "- Importancia (Te칩rica): Era un proxy num칠rico del historial y la reputaci칩n del equipo de autores.\n",
    "- Hip칩tesis: Los art칤culos retractados podr칤an ser escritos por equipos con una media de publicaciones previas significativamente menor (autores novatos o fraudulentos).\n",
    "- Raz칩n del Descarte: Inviabilidad Computacional. La API de OpenAlex no proporciona el works_count del autor en la consulta del art칤culo. Obtenerlo requerir칤a una llamada extra a la API por cada autor de cada art칤culo (~250,000+ llamadas adicionales), lo cual es demasiado costoso y lento para el valor que aporta.\n",
    "\n",
    "### Features que inicilamente ibamos a usar pero han acabado descartadas\n",
    "1. is_abstract_retraction_notice:\n",
    "- Significado: Booleano (1/0) que indica si el campo del abstract conten칤a un aviso de retractaci칩n.\n",
    "- Importancia: Es una feature meta sobre la calidad del dato.\n",
    "- Hip칩tesis: El hecho de que el editor reemplace el abstract es una se침al fuerte, aunque ocurre despu칠s de la retractaci칩n (por eso la descartamos). Para el modelo, podr칤a capturar patrones sutiles sobre c칩mo diferentes editoriales manejan las retractaciones.\n",
    "\n",
    "Las siguientes dos, se reemplazaron por citatioins_in_first_2_years para evitar fuga de datos\n",
    "\n",
    "2. citation_count_total:\n",
    "- Significado: El n칰mero total de veces que el art칤culo ha sido citado.\n",
    "- Importancia: Medida cl치sica de impacto.\n",
    "3. citations_per_year:\n",
    "- Significado: Citas totales divididas por la \"edad\" del art칤culo.\n",
    "- Importancia: Una medida de impacto normalizada y mucho m치s justa. Mide la \"velocidad\" a la que un art칤culo acumula citas.\n",
    "- Hip칩tesis: Los art칤culos fraudulentos podr칤an tener un pico inicial de citas que luego decae r치pidamente, o simplemente una velocidad de citaci칩n muy baja.\n",
    "\n",
    "---\n",
    "\n",
    "### Del df_retraction despu칠s de limpiarlo, tenemos estas 21 columnas y 56046 filas:\n",
    "\n",
    "Index(['record_id', 'title', 'subject', 'institution', 'journal', 'publisher',\n",
    "'country', 'author', 'urls', 'article_type', 'retraction_date',\n",
    "'retraction_doi', 'retraction_pub_med_id', 'original_paper_date',\n",
    "'original_paper_doi', 'original_paper_pub_med_id', 'retraction_nature',\n",
    "'reason', 'paywalled', 'notes', 'year'],\n",
    "dtype='object')\n",
    "\n",
    "### Columnas que S칈 usamos (Directa o Indirectamente)\n",
    "- original_paper_doi:\n",
    "    - Uso: Fundamental. Es nuestra \"llave maestra\", la lista de la compra de DOIs que usamos para consultar la API de OpenAlex y enriquecer los datos.\n",
    "- title, subject, institution, journal, publisher, country, author, article_type, original_paper_date (year):\n",
    "    - Uso: Inspiraci칩n y Validaci칩n. No usamos sus datos directamente para el modelo (porque preferimos los datos limpios de la API), pero han sido cruciales para:\n",
    "        1. Formular hip칩tesis: Analizar estas columnas nos ayud칩 a decidir qu칠 features eran importantes (publisher, country, etc.).\n",
    "        2. Validar la extracci칩n: Comparamos los datos de estas columnas con los que obtenemos de la API para asegurarnos de que nuestro extractor funciona correctamente.\n",
    "- paywalled:\n",
    "    - Uso: Inspiraci칩n. Nos llev칩 a crear la feature is_open_access a partir de la API, que es una versi칩n m치s fiable y estandarizada.\n",
    "### Columnas que S칈 a침adiremos al Dataset Final\n",
    "- retraction_nature:\n",
    "    - Uso: Definici칩n del Target. La usamos para filtrar y quedarnos solo con los casos que son \"Retraction\" o \"Expression of concern\", definiendo as칤 qu칠 es un evento \"malo\" que queremos predecir.\n",
    "- reason:\n",
    "    - Uso: La Joya de la Corona. Aunque no es una feature predictiva directa, es crucial para el an치lisis post-modelo. Una vez que el modelo identifica un paper como de \"alto riesgo\", podemos mirar esta columna en nuestros datos de entrenamiento para entender por qu칠 art칤culos similares fueron retractados (ej. \"Fake Peer Review\", \"Paper Mill\"). Inspira la ingenier칤a de features y enriquece la narrativa del proyecto.\n",
    "### Columnas que NO usamos (y por qu칠)\n",
    "- record_id:\n",
    "    - Motivo: Es un identificador interno de Retraction Watch. No tiene valor predictivo ni es una clave 칰til para unir con otras bases de datos.\n",
    "- urls:\n",
    "    - Motivo: Demasiado heterog칠neo y poco estructurado. La URL del DOI ya nos da el enlace can칩nico al art칤culo.\n",
    "- retraction_date:\n",
    "    - Motivo: Fuga de Datos (Data Leakage). Esta es la fecha en que el evento ocurri칩. No podemos usar informaci칩n del futuro para predecir el pasado. Nuestro modelo debe predecir el riesgo de retractaci칩n en el momento de la publicaci칩n, cuando esta fecha a칰n no existe.\n",
    "- retraction_doi, retraction_pub_med_id:\n",
    "    - Motivo: Son los identificadores del aviso de retractaci칩n, no del paper original. No son relevantes para analizar las caracter칤sticas del art칤culo en s칤.\n",
    "- original_paper_pub_med_id:\n",
    "    - Motivo: Redundante. El original_paper_doi es el identificador universal que hemos elegido como nuestra clave principal.\n",
    "- notes:\n",
    "    - Motivo: Texto libre no estructurado. Contiene informaci칩n valiosa para una investigaci칩n manual, pero es muy dif칤cil de procesar para convertirlo en una feature cuantitativa 칰til para el modelo. Lo descartamos por pragmatismo.\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
